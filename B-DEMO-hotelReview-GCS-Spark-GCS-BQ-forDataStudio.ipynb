{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/html":["\n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://aekanun-cluster-307b-m.us-central1-c.c.shining-haiku-318402.internal:46355\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.8</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        "],"text/plain":["<SparkContext master=yarn appName=PySparkShell>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["sc"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from pyspark.sql import functions as sparkf\n","from pyspark.sql.types import *"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["loaded_df = spark.read.json('gs://usjqbewjtps/json/*.json')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["raw_df = loaded_df"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["analysis_df = raw_df.select('id','createdDate','additionalRatings'\\\n","                            ,sparkf.col('location.additionalNames.geo').alias('location_geo')\\\n","                            ,sparkf.col('location.placeType').alias('location_placeType')\\\n","                            ,sparkf.col('location.name').alias('location_name')\\\n","              ,'rating','userProfile.userId'\\\n","                            ,'userProfile.hometown.location.name')\\\n",".withColumnRenamed('rating','rating_col')\\\n",".withColumnRenamed('name','userHometown')\\\n",".withColumn('extracted_additionalRatings',sparkf.explode('additionalRatings'))\\\n",".select(\n","  'id','createdDate','additionalRatings','extracted_additionalRatings'\\\n","    , sparkf.col(\"extracted_additionalRatings\")[\"rating\"].alias(\"rating\")\\\n","    , sparkf.col(\"extracted_additionalRatings\")[\"ratingLabel\"].alias(\"ratingLabel\")\\\n","    ,'location_geo','location_name','rating_col','userId','userHometown','location_placeType'\n",")\\\n",".groupBy('id','createdDate','rating_col','location_placeType','location_name','location_geo'\\\n","         ,'userId','userHometown').pivot('ratingLabel').sum('rating')\\\n",".orderBy('id', ascending= False)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["sparkf_ReplaceNull = sparkf.udf(lambda x: \"UNKNOWN\" if x == None else x)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["final_df = analysis_df\\\n",".withColumnRenamed('Business service (e.g., internet access)','Business_service')\\\n",".withColumn('userHometown',sparkf_ReplaceNull('userHometown'))\\\n",".withColumn('Cleanliness',sparkf.col('Cleanliness').cast(IntegerType()))\\\n",".withColumn('Location',sparkf.col('Location').cast(IntegerType()))\\\n",".withColumn('Rooms',sparkf.col('Rooms').cast(IntegerType()))\\\n",".withColumn('Service',sparkf.col('Service').cast(IntegerType()))\\\n",".withColumn('Sleep Quality',sparkf.col('Sleep Quality').cast(IntegerType()))\\\n",".withColumn('Value',sparkf.col('Value').cast(IntegerType()))\\\n",".withColumn('Business_service'\\\n","            ,sparkf.col('Business_service').cast(IntegerType()))\\\n",".withColumn('Check in / front desk',sparkf.col('Check in / front desk').cast(IntegerType()))\\\n",".withColumn('createdDate',sparkf.to_timestamp('createdDate',format='yyyy-MM-dd'))\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Use the Google Cloud Storage bucket for temporary BigQuery export data used\n","# by the InputFormat. This assumes the Google Cloud Storage connector for\n","# Hadoop is configured.\n","bucket = sc._jsc.hadoopConfiguration().get('fs.gs.system.bucket')\n","project = sc._jsc.hadoopConfiguration().get('fs.gs.project.id')\n","input_directory = 'gs://{}/hadoop/tmp/bigquery/pyspark_input'.format(bucket)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["'dataproc-staging-us-central1-883550361886-6am8uglv'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["bucket"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["'shining-haiku-318402'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["project"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Output Parameters.\n","output_dataset = 'tourism_dataset'\n","output_table = 'tourism_table'"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Stage data formatted as newline-delimited JSON in Google Cloud Storage.\n","output_directory = 'gs://{}/hadoop/tmp/bigquery/pyspark_output'.format(bucket)\n","#partitions = range(word_counts.getNumPartitions())\n","output_files = output_directory + '/part-*'\n","\n","\n","output_files\n","\n","final_df.write.option(\"header\",True).mode('overwrite').format('csv').save(output_directory)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["'gs://dataproc-staging-us-central1-883550361886-6am8uglv/hadoop/tmp/bigquery/pyspark_output/part-*'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["output_files"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#! gsutil ls gs://dataproc-staging-us-central1-883550361886-6am8uglv/hadoop/tmp/bigquery/pyspark_output/"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import subprocess"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Shell out to bq CLI to perform BigQuery import.\n","subprocess.check_call(\n","    'bq load --source_format=CSV  '\n","    '--replace '\n","    '--autodetect '\n","    '{dataset}.{table} {files} '.format(\n","        dataset=output_dataset, table=output_table, files=output_files\n","    ).split())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":5}